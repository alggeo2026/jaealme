import streamlit as st
import time
from datetime import datetime, timedelta

# [ìœ ì§€] 1. ì´ˆê¸° ì„¸ì…˜ ë° í•™ìŠµ ë©”ëª¨ë¦¬ ì„¤ì •
if "messages" not in st.session_state:
    st.session_state.messages = []
if "learning_note" not in st.session_state:
    st.session_state.learning_note = [] 
if "inventory" not in st.session_state:
    st.session_state.inventory = {
        "ìƒìˆ˜": {"last_asked": datetime.now() - timedelta(days=7), "status": "ë³´í†µ"},
        "ì„¸ì œ": {"last_asked": datetime.now() - timedelta(days=20), "status": "ë¶€ì¡±"},
        "ì¹˜ì•½": {"last_asked": datetime.now() - timedelta(days=40), "status": "ë³´í†µ"},
        "ì°¸ê¸°ë¦„": {"last_asked": datetime.now() - timedelta(days=40), "status": "ë³´í†µ"}
    }
if "persona" not in st.session_state:
    st.session_state.persona = "ë¯¼ì•„"

# [ë³´ì™„] 2. ìœ ì—°í•œ í‚¤ì›Œë“œ ë§¤ì¹­ ë‹µë³€ ë¡œì§
def generate_response(user_input):
    # í•™ìŠµëœ ë‚´ìš© ìš°ì„  í™•ì¸ (ë¶€ë¶„ ì¼ì¹˜ë¡œ ê°œì„ )
    correction = next((note['correct'] for note in st.session_state.learning_note if note['wrong'] in user_input), None)
    
    if any(word in user_input for word in ["í‹€ë ¸ì–´", "ì•„ë‹ˆì•¼", "ê·¸ê±° ì•„ëƒ", "ì˜ëª»ì•Œì•˜ì–´"]):
        return "ëª°ë¼ì„œ ê·¸ë¬ì–´ ë¯¸ì•ˆ! ì•Œë ¤ì£¼ë©´ ê³ ì¹˜ê»˜. ë­ê°€ ë§ëŠ” ê±°ì•¼?"
    
    if correction:
        return f"[{st.session_state.persona}] ì•„ ë§ë‹¤, {correction}ë¼ê³  í–ˆì§€! ì´ì œ í™•ì‹¤íˆ ê¸°ì–µë‚˜."

    # í‚¤ì›Œë“œ ê¸°ë°˜ ìœ ì—°í•œ ì‘ëŒ€ (ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ë°˜ì‘í•¨)
    if any(word in user_input for word in ["ì•ˆë…•", "ì•ˆë…•íˆ", "ë°˜ê°€ì›Œ", "í•˜ì´"]):
        return f"[{st.session_state.persona}] ì™”ì–´? ë­ í•„ìš”í•œ ê±° ìˆì–´?"
    elif "ì„¸ì œ" in user_input:
        return f"[{st.session_state.persona}] ì„¸ì œ ê±°ì˜ ë‹¤ ì¨ê°€ë˜ë°, ë” ì‚´ê¹Œ?"
    elif any(word in user_input for word in ["ë¬¼", "ìƒìˆ˜", "ìŒë£Œ"]):
        return f"[{st.session_state.persona}] ìƒìˆ˜ëŠ” ì•„ì§ ë„‰ë„‰í•´ ë³´ì—¬!"
    elif any(word in user_input for word in ["ë°°ì›Œ", "ê°€ë¥´ì³", "ê¸°ì–µí•´"]):
        return f"[{st.session_state.persona}] ì‘! ì–¸ì œë“  ê°€ë¥´ì³ì£¼ë©´ ë°”ë¡œ ë°°ìš¸ê²Œ."
    else:
        # ì—‰ëš±í•œ ëŒ€ë‹µ ë°©ì§€: ëª¨ë¥¼ ë•ŒëŠ” ì†”ì§í•˜ê²Œ ë¬¼ì–´ë³´ê¸°
        return f"[{st.session_state.persona}] ìŒ, '{user_input}'ì€(ëŠ”) ì²˜ìŒ ë“¤ì–´ë´. ì¡°ê¸ˆ ë” ì‰½ê²Œ ë§í•´ì¤„ë˜?"

# --- UI ë ˆì´ì•„ì›ƒ ---
st.set_page_config(page_title="ì¬ì•Œë©”", layout="centered")
st.title(f"ğŸ  ì¬ì•Œë©” v4.0 ({st.session_state.persona})")

# [ë³´ì™„] 3. ìŠ¤í”¼ì»¤ ì ê¸ˆ í•´ì œí˜• ìŒì„± ì¸ì‹ ë¸Œë¦¿ì§€
st.components.v1.html(
    """
    <script>
    const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
    recognition.lang = 'ko-KR';
    
    function updateBtn(text, color) {
        const btn = document.getElementById('micBtn');
        if (btn) {
            btn.innerText = text;
            btn.style.background = color;
        }
    }

    function speak(text) {
        if (!text) return;
        window.speechSynthesis.cancel();
        const msg = new SpeechSynthesisUtterance(text);
        msg.lang = 'ko-KR';
        window.speechSynthesis.speak(msg);
    }

    // ë§ˆì´í¬ ì‹œì‘ ì‹œ 'ë¬´ìŒ'ì„ ë¨¼ì € ì¬ìƒí•˜ì—¬ ë¸Œë¼ìš°ì € ìŠ¤í”¼ì»¤ ê¶Œí•œì„ ë¯¸ë¦¬ íšë“í•©ë‹ˆë‹¤.
    function startWithSound() {
        const dummy = new SpeechSynthesisUtterance(""); 
        window.speechSynthesis.speak(dummy);
        recognition.start();
    }

    recognition.onstart = () => updateBtn('ğŸ¤ ì£¼ì¸ì˜ ë§ì”€ì„ ë“£ëŠ” ì¤‘...', '#28a745');
    recognition.onspeechend = () => updateBtn('ğŸ§  ìƒê° ì¤‘...', '#ffc107');
    
    recognition.onresult = (event) => {
        const text = event.results[0][0].transcript;
        updateBtn('âœ… ì¸ì‹ ì™„ë£Œ: ' + text, '#007bff');
        
        const textArea = window.parent.document.querySelector('textarea[data-testid="stChatInputTextArea"]');
        if (textArea) {
            const setter = Object.getOwnPropertyDescriptor(window.HTMLTextAreaElement.prototype, "value").set;
            setter.call(textArea, text);
            textArea.dispatchEvent(new Event('input', { bubbles: true }));
            
            setTimeout(() => {
                const sendBtn = window.parent.document.querySelector('button[data-testid="stChatInputSubmitButton"]');
                if (sendBtn) sendBtn.click();
            }, 500);
        }
    };

    recognition.onerror = () => updateBtn('âŒ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”', '#dc3545');

    window.addEventListener('message', (e) => {
        if (e.data.type === 'tts') speak(e.data.text);
    });
    </script>
    <button id="micBtn" onclick="startWithSound()" style="width:100%; height:80px; border-radius:20px; background: #FF4B4B; color:white; border:none; font-size:20px; font-weight:bold; cursor:pointer; box-shadow: 0 4px 15px rgba(0,0,0,0.3);">
        ğŸ¤ ëˆŒëŸ¬ì„œ ì¬ì•Œë©”ì—ê²Œ ë§í•˜ê¸°
    </button>
    """,
    height=110,
)

# [ìœ ì§€] 4. ëŒ€í™”ì°½ ì²˜ë¦¬
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

if prompt := st.chat_input("ì¬ì•Œë©”ì—ê²Œ ì§ì ‘ ê°€ë¥´ì¹˜ê¸°"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    if len(st.session_state.messages) > 1 and "ëª°ë¼ì„œ ê·¸ë¬ì–´" in st.session_state.messages[-2]["content"]:
        st.session_state.learning_note.append({"wrong": "ì´ì „ë‚´ìš©", "correct": prompt})
        response = f"[{st.session_state.persona}] ì‘! í™•ì‹¤íˆ ë°°ì› ì–´. '{prompt}'ë¼ê³  ê¸°ì–µí• ê²Œ!"
    else:
        response = generate_response(prompt)
    
    st.session_state.messages.append({"role": "assistant", "content": response})
    
    clean_response = response.replace('[', '').replace(']', '')
    st.components.v1.html(f"<script>window.parent.postMessage({{type: 'tts', text: '{clean_response}'}}, '*');</script>", height=0)
    st.rerun()
